<img width="1376" height="664" alt="AWS_ETL_Pipeline_Architecture" src="https://github.com/user-attachments/assets/0f4095df-400d-45d5-a502-d847d36d8195" />

# üõ†Ô∏è Execution Guide: Event-Driven Serverless ETL Pipeline on AWS


## üìò Introduction

This execution guide provides step-by-step instructions to deploy and run an automated, event-driven ETL (Extract, Transform, Load) pipeline using AWS managed services.

The pipeline processes CSV files uploaded to Amazon S3, applies transformations using AWS Glue, stores the transformed output back into S3, and sends notifications using Amazon SNS. Amazon EventBridge monitors S3 object creation and AWS Glue job state changes to drive the workflow.

The solution is fully serverless, scalable, and requires no infrastructure management.

## üèóÔ∏è Architecture Overview

The architecture follows an event-driven, serverless design where AWS managed services interact through events rather than direct dependencies.

---

### 1. **Amazon S3**

Acts as both the data source and data destination.

- Stores raw and processed data
- Contains two primary folders:
  - `extract/` ‚Üí Stores raw input CSV files uploaded by users
  - `load/` ‚Üí Stores transformed output files generated by AWS Glue
- Triggers downstream processes when new objects are created
- Provides durable and highly available storage


### 2. **AWS Lambda**

Acts as the orchestration layer for the ETL workflow.

- Triggered automatically by S3 PUT events in the `extract/` folder
- Filters and processes `.csv` file uploads
- Programmatically initiates AWS Glue ETL jobs
- Logs execution details to Amazon CloudWatch
- Runs in a fully serverless environment with no infrastructure management


### 3. **AWS Glue**

Handles data transformation and ETL processing.

- Uses the Visual ETL interface
- Reads CSV files from the S3 `extract/` folder
- Applies transformation logic such as duplicate record removal
- Writes processed data to the S3 `load/` folder
- Emits job state change events (Started, Succeeded, Failed)
- Maintains execution history and runtime metrics


### 4. **Amazon EventBridge**

Acts as the central event routing service.

- Monitors Amazon S3 object creation events
- Captures AWS Glue job state change events
- Routes events to multiple targets simultaneously
- Sends notifications to SNS topics
- Forwards events to CloudWatch Logs for auditing
- Operates on the default event bus using custom rules


### 5. **Amazon SNS**

Provides notification and alerting capabilities.

- Receives event notifications from EventBridge
- Sends email alerts for:
  - S3 object upload events
  - Glue job state changes (Started, Succeeded, Failed)
- Manages email subscriptions with confirmation workflow
- Supports multiple subscribers


### 6. **Amazon CloudWatch**

Provides centralized logging and monitoring.

- Stores logs from:
  - AWS Lambda executions
  - EventBridge rule invocations
  - AWS Glue job runs
- Enables monitoring, troubleshooting, and auditing
- Maintains timestamped log streams
- Organizes logs using dedicated log groups


### 7. **AWS IAM**

Ensures secure access and authorization across services.

- Implements role-based access control
- Manages separate roles for:
  - Lambda execution with S3 and Glue permissions
  - Glue ETL jobs with S3 and CloudWatch access
  - EventBridge rules invoking SNS and CloudWatch
- Enforces least-privilege access principles
- Controls service-to-service authentication

---

## üéØ Why This Project?

This project showcases a real-world, event-driven data processing architecture on AWS.

- Demonstrates serverless ETL pipeline design
- Integrates multiple AWS managed services
- Includes monitoring and alerting using native AWS tools
- Eliminates server management
- Ensures scalability and cost efficiency
- Suitable for production-style data engineering workloads

---

## ‚ú® Key Features

- Fully automated ETL pipeline
- Event-driven and serverless architecture
- Near real-time data processing
- Visual ETL job design using AWS Glue
- Email notifications for data and job events
- Centralized logging and monitoring
- Scalable and cost-efficient design

---

## üõ†Ô∏è Execution Workflow

---

## I. Amazon S3 Bucket Setup

1. Log in to the AWS Management Console  
2. Navigate to **Amazon S3**
3. Click on **Create bucket**

**Bucket Configuration:**
- Bucket type: General purpose
- Bucket name: `etl-pipeline-bucket-0701`
- Region: Default
- Leave all other settings as default

4. Click **Create bucket**
5. Open the created bucket
6. Click **Create folder** and create:
   - `extract/` ‚Üí Input CSV files
   - `load/` ‚Üí Transformed output files

---

## II. AWS Lambda Function Configuration

1. Navigate to **AWS Lambda**
2. Click **Create function**

**Basic Configuration:**
- Function name: `s3-object-create-glue-trigger`
- Runtime: Python 3.14

**Execution Role:**
- Select **Create a new role with basic Lambda permissions**

3. Click **Create function**

---

### Add S3 Trigger

1. Click **Add trigger**
2. Configure trigger:
   - Trigger source: S3
   - Bucket: `etl-pipeline-bucket-0701`
   - Event type: PUT
   - Prefix: `extract/`
   - Suffix: `.csv`
3. Acknowledge recursive invocation
4. Click **Add**

---

### Lambda Code Deployment

1. Navigate to the **Code** tab
2. Replace the code with the required Lambda function code
3. Click **Deploy**
4. Click **Test**, create a test event, and invoke the function

---

## III. IAM Role Update for Lambda

1. Navigate to **IAM Console**
2. Go to **Roles**
3. Select `s3-object-create-glue-trigger-role-*`
4. Click **Add permissions** ‚Üí **Attach policies**

**Attach the following policies:**
- `AmazonS3FullAccess`
- `AWSGlueConsoleFullAccess`

5. Save changes

---

## IV. Lambda Execution Monitoring

1. Navigate back to the Lambda function
2. Open the **Monitor** tab
3. Click **View logs in CloudWatch**
4. Review log streams and timestamps

---

## V. AWS Glue Visual ETL Job Creation

1. Navigate to **AWS Glue Dashboard**
2. Click **Visual ETL**
3. Click **Create Job**

### Add Source Node
- Source type: Amazon S3
- S3 source type: S3 location
- S3 URL: `extract/` folder
- Data format: CSV

---

## VI. IAM Role Creation for AWS Glue

1. Navigate to **IAM Console**
2. Click **Create role**

**Trusted Entity:**
- AWS service
- Use case: Glue

**Attach Policies:**
- `AmazonS3FullAccess`
- `AmazonCloudWatchEvidentlyFullAccess`

**Role Name:**
- `S3TriggeredGlueETLRole`

3. Create the role

---

## VII. AWS Glue Job Configuration

1. Return to AWS Glue
2. Select the created IAM role
3. Click **Start session**

### Add Transformation
- Transform: Drop Duplicates
- Parent node: Amazon S3

### Add Target
- Target: Amazon S3
- Parent node: Drop Duplicates
- Format: CSV
- Compression: None
- Target location: `load/`
- File output: 1 file

---

## VIII. Data Preview and Sample File Upload

1. Open the S3 Source node
2. Observe no data initially
3. Upload `data.csv` into `extract/` folder in S3
4. Refresh Glue Data Preview to validate records

---

## IX. Glue Job Execution

1. Save the job as `ETLGlueJob`
2. Click **Run**
3. Monitor job status under **Runs**
4. Verify transformed file appears in `load/` folder

---

## X. Amazon SNS Topic and Subscription Setup

1. Navigate to **Amazon SNS**
2. Click **Create topic**

**Topic Configuration:**
- Type: Standard
- Name: `ETLJobNotification`
- Display name: `AWS SNS`

3. Create topic

### Create Subscription
- Protocol: Email
- Endpoint: Your email address

4. Confirm subscription via email

---

## XI. Amazon EventBridge Rule for S3 Events

1. Navigate to **Amazon EventBridge**
2. Select **Default event bus**
3. Click **Create rule**
4. Disable Visual rule builder

**Rule Name:**
- `S3ObjectUploadTriggerRule`

### Event Pattern
- Source: AWS services
- Service: S3
- Event type: Object Created

### Targets
- Target 1: SNS Topic ‚Üí `ETLJobNotification`
- Target 2: CloudWatch Log Group ‚Üí `s3-object-upload-events`

5. Create rule

---

## XII. S3 EventBridge Configuration

1. Navigate to S3 bucket
2. Open **Properties**
3. Enable **Send notifications to Amazon EventBridge**
4. Upload a CSV file
5. Verify:
   - Email notification received
   - CloudWatch logs populated

---

## XIII. Lambda Update for Glue Job Trigger

1. Update Lambda code with Glue job name: `ETLGlueJob`
2. Deploy updated code
3. Test the function
4. Verify Glue job runs automatically

---

## XIV. EventBridge Rule for Glue Job Status

1. Create a new EventBridge rule

**Rule Name:**
- `GlueJobStatusChangeRule`

### Event Source
- AWS Service: Glue
- Event type: Job State Change

### Targets
- SNS Topic ‚Üí `ETLJobNotification`
- CloudWatch Log Group ‚Üí `glue-job-status-change-events`

2. Create rule

---

## XV. Glue Job Status Monitoring

1. Trigger Lambda again
2. Observe new Glue job run
3. Receive SNS email for job status
4. Review logs in CloudWatch

---

## XVI. Resource Cleanup

Delete resources in the following order to avoid charges:

1. EventBridge Rules
2. SNS Subscriptions
3. SNS Topics
4. Glue Jobs
5. IAM Roles
6. IAM Policies
7. CloudWatch Log Groups
8. Lambda Functions
9. Empty all S3 Buckets
10. Delete all S3 Buckets

---

## ‚úÖ Conclusion

This project implements a complete, automated ETL pipeline using AWS managed services. It demonstrates a production-style, event-driven architecture that processes data without managing servers.

By integrating Amazon S3, AWS Lambda, AWS Glue, Amazon EventBridge, Amazon SNS, CloudWatch, and IAM, the solution achieves scalability, observability, reliability, and operational simplicity‚Äîmaking it suitable for both learning and real-world data engineering workloads.
